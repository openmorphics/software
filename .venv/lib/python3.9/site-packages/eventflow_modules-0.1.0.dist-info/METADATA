Metadata-Version: 2.4
Name: eventflow-modules
Version: 0.1.0
Classifier: License :: OSI Approved :: BSD License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: eventflow-core
Requires-Dist: matplotlib ; extra == 'audio-viz'
Requires-Dist: plotly ; extra == 'audio-viz'
Requires-Dist: sounddevice ; extra == 'audio-viz'
Provides-Extra: audio-viz
Summary: Domain-specific modules for EventFlow
Author: EventFlow Team
License: BSD-3-Clause
Requires-Python: >=3.8
Description-Content-Type: text/markdown; charset=UTF-8; variant=GFM

# EventFlow Domain Modules


## Native vision stub and EF_NATIVE

This package provides an optional Rust-backed vision stub for early acceleration experiments:
- Loader module: eventflow_modules._rust (exposes `native` when available)
- Native module name: eventflow_modules._rust._vision_native
- Current kernel: optical_flow_stub(frames: np.ndarray[f32, HxW]) → np.ndarray[f32, HxW] (copy placeholder)

EF_NATIVE toggle behavior follows eventflow-core:
- EF_NATIVE=1 → force native if available; warn and fall back if import fails
- EF_NATIVE=0 → force pure Python
- Unset → auto; use native when available

Quick check:
- from eventflow_modules._rust import native as vis_native
- print(getattr(vis_native, "RUST_ENABLED", False))

## Installation and local build

- pip install eventflow-modules  (installs eventflow-core dependency)
- Local dev build:
  - python -m pip install -U maturin
  - cd eventflow-modules
  - python -m maturin develop -r

Supported wheels target Python 3.8–3.12 with abi3 across macOS universal2, manylinux_2_28/musllinux, and Windows MSVC.

## Macro-benchmark example

- python -m pip install -U pytest pytest-benchmark numpy
- pytest -q eventflow-modules/tests/test_bench_optical_flow.py -k bench --benchmark-only --benchmark-autosave

CI captures autosaved results from .benchmarks and uploads artifacts (see bench.yml in the repo).

## Roadmap note

The real optical flow kernel is in progress; optical_flow_stub is a drop-in shape/ABI placeholder to enable data plumbing and benchmarking.

---

## Always-on Audio (VAD + KWS)

This package now includes an always-on audio demonstration module with a shared event-driven frontend (STFT → Mel) and dual heads:
- VAD: Event coincidence over Mel bands
- KWS: LIF neuron integration over Mel features

Core builder and runners:
- [build_always_on_graph()](eventflow-modules/eventflow_modules/audio/always_on.py:77)
- [run_wav_file()](eventflow-modules/eventflow_modules/audio/always_on.py:567)
- [run_mic_live()](eventflow-modules/eventflow_modules/audio/always_on.py:595)
- SAL/bands variants:
  - [build_always_on_bands_graph()](eventflow-modules/eventflow_modules/audio/always_on.py:715)
  - [run_wav_bands_sal()](eventflow-modules/eventflow_modules/audio/always_on.py:777)
  - [run_mic_bands_sal()](eventflow-modules/eventflow_modules/audio/always_on.py:805)

CLI entrypoint (added in [pyproject.toml](eventflow-modules/pyproject.toml:36)):
- ef-audio-demo file --path examples/wakeword/audio.wav --viz plotly --energy both
- ef-audio-demo mic --duration 15 --viz mpl --energy arm

Examples:
- Offline WAV demo: [examples/always_on_audio/file_demo.py](examples/always_on_audio/file_demo.py)
- Microphone demo: [examples/always_on_audio/mic_demo.py](examples/always_on_audio/mic_demo.py)

Optional dependencies (install as extras):
- pip install -e ./eventflow-modules[audio-viz]
  - Installs matplotlib, plotly, sounddevice

Notes:
- Microphone capture uses sounddevice (optional); if unavailable, use file mode or SAL band sources.
- Energy modeling provides ARM MCU vs Laptop CPU comparisons (heuristic constants; calibrate for hardware).
- Visualization falls back to Matplotlib if Plotly is not available.

Programmatic usage:
- Python API examples:
  - Build and run WAV:
    - from eventflow_modules.audio.always_on import build_always_on_graph, run_wav_file
    - g = build_always_on_graph()
    - result = run_wav_file("examples/wakeword/audio.wav", viz="none", energy_models="both")
  - Build bands graph and run SAL WAV bands:
    - from eventflow_modules.audio.always_on import build_always_on_bands_graph, run_wav_bands_sal
    - result = run_wav_bands_sal("examples/wakeword/audio.wav", viz="none")

Bench harness:
- A benchmarking utility will be available under examples/always_on_audio/bench.py to sweep n_fft, hop, and n_mels across energy models and write CSV/JSON outputs.

